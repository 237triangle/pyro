{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking an Unknown Number of Objects\n",
    "\n",
    "While SVI can be used to learn components and assignments of a mixture model, pyro.contrib.tracking provides more efficient inference algorithms to estimate assignments. This notebook demonstrates how to use the `MarginalAssignmentPersistent` inside SVI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "from torch.distributions import constraints\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "from pyro.contrib.tracking.assignment import MarginalAssignmentPersistent\n",
    "from pyro.infer import SVI, TraceEnum_ELBO\n",
    "from pyro.optim import ClippedAdam\n",
    "\n",
    "from datagen_utils import generate_observations, get_positions\n",
    "from plot_utils import plot_solution, plot_exists_prob\n",
    "%matplotlib inline\n",
    "pyro.enable_validation(True)\n",
    "smoke_test = ('CI' in os.environ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "It's tricky to define a fully generative model, so instead we'll separate our data generation process `generate_data()` from a factor graph `model()` that will be used in inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@poutine.broadcast\n",
    "def model(args, observations):\n",
    "    with pyro.iarange(\"objects\", args.max_num_objects):\n",
    "        exists = pyro.sample(\"exists\",\n",
    "                             dist.Bernoulli(args.expected_num_objects / args.max_num_objects))\n",
    "        with poutine.scale(scale=exists):\n",
    "            states_loc = pyro.sample(\"states\", dist.Normal(0., 1.).expand([2]).independent(1))\n",
    "            positions = get_positions(states_loc, args.num_frames)\n",
    "    with pyro.iarange(\"detections\", observations.shape[1]):\n",
    "        with pyro.iarange(\"time\", args.num_frames):\n",
    "            # The combinatorial part of the log prob is approximated to allow independence.\n",
    "            is_observed = (observations[..., -1] > 0)\n",
    "            with poutine.scale(scale=is_observed.float()):\n",
    "                assign = pyro.sample(\"assign\",\n",
    "                                     dist.Categorical(torch.ones(args.max_num_objects + 1)))\n",
    "            is_spurious = (assign == args.max_num_objects)\n",
    "            is_real = is_observed & ~is_spurious\n",
    "            num_observed = is_observed.float().sum(-1, True)\n",
    "            # TODO Make these Bernoulli probs more plausible.\n",
    "            pyro.sample(\"is_real\",\n",
    "                        dist.Bernoulli(args.expected_num_objects / observations.shape[1]),\n",
    "                        obs=is_real.float())\n",
    "            pyro.sample(\"is_spurious\",\n",
    "                        dist.Bernoulli(args.expected_num_spurious / observations.shape[1]),\n",
    "                        obs=is_spurious.float())\n",
    "\n",
    "            # The remaining continuous part is exact.\n",
    "            observed_positions = observations[..., 0]\n",
    "            with poutine.scale(scale=is_real.float()):\n",
    "                bogus_position = positions.new_zeros(args.num_frames, 1)\n",
    "                augmented_positions = torch.cat([positions, bogus_position], -1)\n",
    "                predicted_positions = augmented_positions[:, assign]\n",
    "                pyro.sample(\"real_observations\",\n",
    "                            dist.Normal(predicted_positions, args.emission_noise_scale),\n",
    "                            obs=observed_positions)\n",
    "            with poutine.scale(scale=is_spurious.float()):\n",
    "                pyro.sample(\"spurious_observations\", dist.Normal(0., 1.),\n",
    "                            obs=observed_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This guide uses a smart assignment solver but a naive state estimator. A smarter implementation would use message passing also for state estimation, e.g. a Kalman filter-smoother."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@poutine.broadcast\n",
    "def guide(args, observations):\n",
    "    # Initialize states randomly from the prior.\n",
    "    states_loc = pyro.param(\"states_loc\", lambda: torch.randn(args.max_num_objects, 2))\n",
    "    positions = get_positions(states_loc, args.num_frames)\n",
    "\n",
    "    # Solve soft assignment problem.\n",
    "    real_dist = dist.Normal(positions.unsqueeze(-2), args.emission_noise_scale)\n",
    "    spurious_dist = dist.Normal(0., 1.)\n",
    "    is_observed = (observations[..., -1] > 0)\n",
    "    observed_positions = observations[..., 0].unsqueeze(-1)\n",
    "    assign_logits = (real_dist.log_prob(observed_positions) -\n",
    "                     spurious_dist.log_prob(observed_positions) +\n",
    "                     math.log(args.expected_num_objects * args.emission_prob /\n",
    "                              args.expected_num_spurious))\n",
    "    assign_logits[~is_observed] = -float('inf')\n",
    "    exists_logits = torch.empty(args.max_num_objects).fill_(\n",
    "        math.log(args.expected_num_objects / args.max_num_objects))\n",
    "    assignment = MarginalAssignmentPersistent(exists_logits, assign_logits, args.bp_iters)\n",
    "\n",
    "    with pyro.iarange(\"objects\", args.max_num_objects):\n",
    "        exists = pyro.sample(\"exists\", assignment.exists_dist, infer={\"enumerate\": \"parallel\"})\n",
    "        with poutine.scale(scale=exists):\n",
    "            pyro.sample(\"states\", dist.Delta(states_loc).independent(1))\n",
    "    with pyro.iarange(\"detections\", observations.shape[1]):\n",
    "        with poutine.scale(scale=is_observed.float()):\n",
    "            with pyro.iarange(\"time\", args.num_frames):\n",
    "                pyro.sample(\"assign\", assignment.assign_dist, infer={\"enumerate\": \"parallel\"})\n",
    "\n",
    "    return assignment, states_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a global config object to make it easy to port code to `argparse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = type('Args', (object,), {})  # A fake ArgumentParser.parse_args() result.\n",
    "\n",
    "args.num_frames = 10\n",
    "args.max_num_objects = 400\n",
    "args.expected_num_objects = 2.\n",
    "args.expected_num_spurious = 0.1  # If this is too small, BP will be unstable.\n",
    "args.emission_prob = 0.9          # If this is too large, BP will be unstable.\n",
    "args.emission_noise_scale = 0.2   # If this is too small, SVI will see flat gradients.\n",
    "args.bp_iters = 20\n",
    "args.svi_iters = 101\n",
    "\n",
    "assert args.max_num_objects >= args.expected_num_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(0)\n",
    "true_states, true_positions, observations = generate_observations(args)\n",
    "true_num_objects = len(true_states)\n",
    "max_num_detections = observations.shape[1]\n",
    "assert true_states.shape == (true_num_objects, 2)\n",
    "assert true_positions.shape == (args.num_frames, true_num_objects)\n",
    "assert observations.shape == (args.num_frames, max_num_detections, 1+1)\n",
    "print(\"generated {:d} detections from {:d} objects\".format(\n",
    "    (observations[..., -1] > 0).long().sum(), true_num_objects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, our solution should replicate importance sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(1)  # Use a different seed from data generation\n",
    "pyro.clear_param_store()\n",
    "assignment, states_loc = guide(args, observations)\n",
    "p_exists = assignment.exists_dist.probs\n",
    "positions = get_positions(states_loc, args.num_frames)\n",
    "plot_solution(observations, p_exists, positions, true_positions, args, 'Before training')\n",
    "plot_exists_prob(p_exists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pyro.set_rng_seed(1)  # Use a different seed from data generation\n",
    "pyro.clear_param_store()\n",
    "infer = SVI(model, guide, ClippedAdam({\"lr\": 0.1}), TraceEnum_ELBO(max_iarange_nesting=2))\n",
    "losses = []\n",
    "for epoch in range(args.svi_iters if not smoke_test else 2):\n",
    "    loss = infer.step(args, observations)\n",
    "    if epoch % 20 == 0:\n",
    "        print(\"epoch {: >4d} loss = {}\".format(epoch, loss))\n",
    "    losses.append(loss)\n",
    "pyplot.plot(losses);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "Currently it looks like we're getting stuck in a local mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment, states_loc = guide(args, observations)\n",
    "p_exists = assignment.exists_dist.probs\n",
    "positions = get_positions(states_loc, args.num_frames)\n",
    "plot_solution(observations, p_exists, positions, true_positions, args, 'After training')\n",
    "plot_exists_prob(p_exists)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
